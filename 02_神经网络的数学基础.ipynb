{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 初始神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T01:19:37.628657Z",
     "start_time": "2019-05-27T01:19:25.140943Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T01:19:38.841727Z",
     "start_time": "2019-05-27T01:19:38.836727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images.shape =  (60000, 28, 28)\n",
      "test_images.shape =  (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print('train_images.shape = ', train_images.shape)\n",
    "print('test_images.shape = ', test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T01:19:41.548882Z",
     "start_time": "2019-05-27T01:19:41.267866Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, input_shape=(28 * 28,), activation='relu'))\n",
    "network.add(layers.Dense(10, activation='softmax'))  # 该层返回由10个概率值组成的数组"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "relu运算和加法都是逐元素的运算，即该运算独立地应用于张量中的每个元素，也就是说，这些运算非常适合大规模并行运算。\n",
    "_____\n",
    "**层**：从输入数据中提取表示。大多数深度学习都是将简单的层链接起来，从而实现渐进式的数据蒸馏（data distillation）。\n",
    "\n",
    "- **损失函数**：网络如何衡量在训练数据上的性能，即网络如何朝着正确的方向前进。\n",
    "- **优化器**：基于训练数据和损失函数来更新网络的机制。\n",
    "- 在训练和测试过程中需要监控的指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T01:19:44.241036Z",
     "start_time": "2019-05-27T01:19:44.196033Z"
    }
   },
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据预处理：将其变换为网络要求的形状，并缩放到所有值都在$[0,1]$区间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T01:19:46.624172Z",
     "start_time": "2019-05-27T01:19:46.356157Z"
    }
   },
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对标签进行分类编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T01:24:36.418747Z",
     "start_time": "2019-05-27T01:24:36.407747Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T01:38:47.438423Z",
     "start_time": "2019-05-27T01:37:35.788325Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0222 - acc: 0.9934\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0171 - acc: 0.9951\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0132 - acc: 0.9964\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0100 - acc: 0.9973\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0081 - acc: 0.9979\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0062 - acc: 0.9984\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0050 - acc: 0.9987\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0038 - acc: 0.9989\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0030 - acc: 0.9991\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0025 - acc: 0.9995\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0019 - acc: 0.9996\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0017 - acc: 0.9996\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0013 - acc: 0.9997\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0011 - acc: 0.9998\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 9.9668e-04 - acc: 0.9998\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 8.6331e-04 - acc: 0.9998\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 7.7995e-04 - acc: 0.9999\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 7.5817e-04 - acc: 0.9999\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 7.4798e-04 - acc: 0.9998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c6ef748>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T01:39:59.411539Z",
     "start_time": "2019-05-27T01:39:58.973514Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 43us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T01:41:04.695273Z",
     "start_time": "2019-05-27T01:41:04.689273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss =  0.10312116933780617\n",
      "test_acc =  0.9833\n"
     ]
    }
   ],
   "source": [
    "print('test_loss = ', test_loss)\n",
    "print('test_acc = ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 神经网络的数据表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **张量**：是矩阵向任意维度的推广。\n",
    "- **标量**（0D张量）：仅包含一个数字的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T01:52:12.391463Z",
     "start_time": "2019-05-27T01:52:12.386463Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "x = np.array(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **向量**（1D张量）：数字组成的数组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T01:55:12.518766Z",
     "start_time": "2019-05-27T01:55:12.513766Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.array([12, 3, 6, 12, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **矩阵**（2D张量）：向量组成的数组。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "张量的关键属性：\n",
    "1. 轴的个数\n",
    "2. 形状：表示张量沿每个轴的维度大小，如3D张量的形状为$(3, 3, 5)$\n",
    "3. 数据类型：可为float32、uint8、float64等。张量存储在预先分配的连续内存中，而字符串的长度是可变的，无法用这种方式存储。\n",
    "______\n",
    "\n",
    "深度学习中所有数据张量的第一个轴都是样本轴。\n",
    "\n",
    "需处理的数据张量类别：\n",
    "1. 向量数据：2D张量，形状为$(sample, features)$\n",
    "2. 时间序列数据：3D张量，形状为$(samples, timesteps, features)$\n",
    "3. 图像：4D张量，形状为$(samples, height, width, channels)$\n",
    "4. 视频：5D张量，形状为$(samples, frames, height, width, channels)$\n",
    "\n",
    "股票价格序列集：每一分钟，将股票的close、open、low、high保存下来，每分钟被编码为一个4D向量，整个交易日被编码为一个形状为$(240, 4)$的2D张量，200天的数据则保存为一个形状为$(200, 240, 4)$的3D张量中。每个样本是一天的股票数据。\n",
    "_____\n",
    "深度神经网络学到的所有变换都可以简化为数值数据张量上的一些张量运算。\n",
    "\n",
    "深度学习将复杂的几何变换逐步分解为一长串基本的几何变换，这与人类展开纸球所采取的策略大致相同。\n",
    "____\n",
    "\n",
    "网络训练步骤：\n",
    "1. 抽取训练样本$x$和对应目标$y$组成的数据批量；\n",
    "2. 在$x$上运行网络（前向传播），得到预测值y_pred；\n",
    "3. 计算网络在这批数据上的损失，用于衡量y_pred和$y$之间的距离；\n",
    "4. 更新网络的所有权重，使网络在这批数据上的损失略微下降。\n",
    "\n",
    "更新权重的方法：\n",
    "1. 小批量随机梯度下降（SGD）：利用网络中所有运算都是可微的这一事实，计算损失相对于网络系数的梯度，然后向梯度的反方向改变系数$W-=step * gradient$，从而使损失降低。\n",
    "2. 带动量的SGD、Adagrad、RMSProp等\n",
    "\n",
    "动量解决了SGD的两个问题：1）收敛速度；2）局部极小点。\n",
    "> 其更新参数$w$时，不仅要考虑当前的梯度值，还有考虑上一次的参数更新。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______\n",
    "**反向传播**：从最终损失值开始，从最顶层反向作用至最底层，利用链式法则计算每个参数对损失值的贡献大小。\n",
    "\n",
    "**损失**：在训练过程中需要最小化的量，因此，它能够衡量当前任务是否已成功解决。\n",
    "\n",
    "**优化器**：使用损失梯度更新参数的具体方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T01:54:21.492645Z",
     "start_time": "2019-05-28T01:54:21.484645Z"
    }
   },
   "source": [
    "#### 参考链接\n",
    "- https://blog.csdn.net/u012759136/article/details/52302426\n",
    "- https://blog.csdn.net/weixin_42398658/article/details/84525917"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
