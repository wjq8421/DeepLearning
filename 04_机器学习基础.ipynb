{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 如何衡量泛化能力，即如何评估机器学习模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "评估模型的重点是将数据划分为三个集合：训练集、验证集、测试集。在训练数据上训练模型，在验证数据上评估模型。一旦找到最佳参数，就在测试数据上最后测试一次。\n",
    "> 原因在于开发模型时总是需要调节模型配置，比如选择层数或每层大小。这个调节过程需要使用模型在验证数据上的性能作为反馈信号。因此，如果基于模型在验证集上的性能来调节模型配置，会很快导致模型在验证集上过拟合，即使你并没有在验证集上直接训练模型也会如此。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "训练数据很少时可以使用的评估方法：\n",
    "1. 简单的留出验证\n",
    "> 留出一定比例的数据作为测试集。在剩余数据上划分为训练集和验证集用以评估模型。\n",
    "\n",
    "缺点：如果可用的数据很少，那么可能验证集和测试集包含的样本太少，从而无法在统计学上代表数据。即如果在划分数据前进行不同的随机打乱，最终得到的模型性能差别很大，那么就存在这个问题。\n",
    "\n",
    "2. K折验证\n",
    "> 将数据划分为大小相同的$K$个分区。对于每个分区$i$，在剩余的$K-1$个分区上训练模型，然后在分区$i$上评估模型。最终分数等于$K$个分数的平均值。\n",
    "\n",
    "3. 带有打乱数据的重复K折验证\n",
    "> $P$次使用$K$折验证，在每次将数据划分为$K$个分区之前都先将数据打乱。最终分数是每次$K$折验证分数的平均值。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "#### 神经网络的数据预处理\n",
    "1. 神经网络的所有输入和目标都必须是浮点数张量。\n",
    "\n",
    "为了让网络的学习变得更容易，神经网络的输入数据应具有以下特征：\n",
    "1. 取值较小：大部分取值应在0~1范围或-1~1范围内。\n",
    "2. 同质性：所有特征的取值都应该在大致相同的范围内。\n",
    "\n",
    "一般来说，对于神经网络，将缺失值设置为0是安全的，只要0不是一个有意义的值。网络能够从数据中学到0意味着确实数据，并且会忽略这个值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "#### 特征工程\n",
    "> 本质：用更简单的方式表述问题，从而使问题变得更容易。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "#### 降低过拟合的方法\n",
    "> 调节模型允许存储的信息量，或对模型允许存储的信息加以约束。\n",
    "\n",
    "1. 获取更多的训练数据\n",
    "\n",
    "2. 减小网络大小\n",
    "> 深度学习模型通常都很擅长拟合训练数据，但真正的挑战在于泛化，而不是拟合。同时，使用的模型应该具有足够多的参数，以防欠拟合，即模型应避免记忆资源不足。\n",
    "\n",
    "要找到合适的模型大小，一般的工作流程是开始选择相对较少的层和参数，然后逐渐增加层的大小或增加新层，直到这种增加对验证损失的影响变得很小。\n",
    "\n",
    "3. 添加权重正则化\n",
    "> 强制让模型权重只能取较小的值，从而限制模型的复杂度，这使得权重值的分布更加规则。其实现方法是向网络损失函数中添加与较大权重值相关的成本。\n",
    "\n",
    "\n",
    "- L1正则化：添加的成本与权重系数的绝对值成正比。\n",
    "- L2正则化：添加的成本与权重系数的平方成正比，也叫权重衰减（weight decay）。\n",
    "\n",
    "该惩罚项只在训练时添加，所以这个网络的训练损失会比测试损失大很多。\n",
    "\n",
    "4. 添加dropout正则化\n",
    "> 在训练过程中随机将该层的一些输出特征舍弃（设置为0）。dropout比率是被设为0的特征所占的比例，通常在0.2~0.5范围内。而测试时，没有单元被舍弃，而该层的输出值需要按dropout比率缩小。\n",
    "\n",
    "5. 尝试不同的超参数：每层的单元个数、优化器的学习率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "#### 机器学习工作流程\n",
    "1. 定义问题，收集数据集\n",
    "2. 选择衡量成功的指标\n",
    "3. 确定评估方法\n",
    "4. 准备数据\n",
    "5. 开发比基准更好的模型\n",
    "6. 扩大模型规模，开发过拟合的模型\n",
    "7. 模型正则化与调节超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
